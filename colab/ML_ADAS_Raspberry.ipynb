{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn5DGHVs4eTB"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iE-9dFpKiND"
      },
      "outputs": [],
      "source": [
        "# instalacja TensorFlow Hub\n",
        "!pip install tensorflow_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xU-bhp8MonG"
      },
      "outputs": [],
      "source": [
        "# import bibliotek\n",
        "from PIL import Image\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd \n",
        "from sklearn.metrics import accuracy_score\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqkZA8SW4m5p"
      },
      "source": [
        "# Output configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpfyH7ouqODX"
      },
      "outputs": [],
      "source": [
        "# połączenie projektu z dyskiem Google, dzie znajdują się pliki .zip ze zbiorami danych\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "model_dir = '/content/gdrive/My Drive/Colab Notebooks'\n",
        "\n",
        "# zdefiniowanie ścieżek wyjść (output path)\n",
        "OUTPUT_ROOT_DIR = os.path.join(model_dir, \"/output\")\n",
        "OUTPUT_TFLITE_MODEL = os.path.join(OUTPUT_ROOT_DIR, \"/retrained_graph_mv1_100_224.tflite\")\n",
        "OUTPUT_LABELS = os.path.join(OUTPUT_ROOT_DIR, \"/retrained_labels_mv1_100_224.txt\")\n",
        "OUTPUT_READABLE_LABELS = os.path.join(OUTPUT_ROOT_DIR, \"/labels_readable.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYABzZEK4sbN"
      },
      "source": [
        "# Model configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYxRB2Hx4vxi"
      },
      "outputs": [],
      "source": [
        "# dobór \n",
        "SELECTED_MOBILENET = \"https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4\"\n",
        "\n",
        "# wymiary obrazów ze zbioru wejściowego\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "MODEL_INPUT_HEIGHT = 224\n",
        "MODEL_INPUT_WIDTH = 224\n",
        "\n",
        "# średnia i odchylenie standardowe wyjścia - wynikają ze specyfiki sieci\n",
        "MODEL_INPUT_MEAN = 0\n",
        "MODEL_INPUT_STD = 255\n",
        "\n",
        "# warstwa wejściowa sieci MobileNet v1 ma nazwę \"Placeholder\"\n",
        "MODEL_INPUT_LAYER_NAME = \"Placeholder\"\n",
        "# warstwa wyjściowa ma nazwę \"final_result\"\n",
        "MODEL_OUTPUT_LAYER_NAME = \"final_result\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUxGq-av4zi4"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_ymyG6oEIZZ"
      },
      "outputs": [],
      "source": [
        "#!rm -rf '{model_dir}'\n",
        "#os.makedirs(model_dir, exist_ok=True)\n",
        "!ls -ltra '{model_dir}'/.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oxbb44S447WS"
      },
      "outputs": [],
      "source": [
        "TMP_DATA_DIR = f\"{model_dir}/dataset/tmp\"\n",
        "TMP_LABELS_DIR = os.path.join(TMP_DATA_DIR, \"GTSRB/Final_Test\")\n",
        "\n",
        "TRAINING_DATA_DIR = \"dataset/training\"\n",
        "VALIDATION_DATA_DIR = \"dataset/validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XecbgwJ15CF_"
      },
      "outputs": [],
      "source": [
        "# ścieżki do \n",
        "to_unpack = [\n",
        "    (f\"{TMP_DATA_DIR}/Final_Training_Images.zip\"),\n",
        "    (f\"{TMP_DATA_DIR}/Final_Test_Images.zip\"),\n",
        "    (f\"{TMP_DATA_DIR}/Final_Test_GT.zip\")\n",
        "]\n",
        " \n",
        "for file in to_unpack:\n",
        "    # print(\"Unzipping {} to {}...\".format(file, ))\n",
        "    with zipfile.ZipFile(file,\"r\") as zip_ref:\n",
        "        zip_ref.extractall(TMP_DATA_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdJxevr55Okx"
      },
      "source": [
        "# Training, validation, labels - prepare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXIAyRMd5Yj-"
      },
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFVtpRPJ5Tir"
      },
      "outputs": [],
      "source": [
        "# etykiety klas\n",
        "label_map = {\n",
        "    0: '20_speed',\n",
        "    3: '60_speed',\n",
        "    12: 'right_of_way_general',\n",
        "    13: 'give_way',\n",
        "    14: 'stop',\n",
        "    20: 'attention_right_turn',\n",
        "    22: 'attention_bumpers',\n",
        "    40: 'turn_circle',\n",
        "}\n",
        "\n",
        "if not os.path.exists(OUTPUT_ROOT_DIR):\n",
        "        os.makedirs(OUTPUT_ROOT_DIR)\n",
        "\n",
        "file = open(OUTPUT_READABLE_LABELS, 'w')\n",
        "for key, val in sorted(label_map.items()):\n",
        "    file.write(\"{}\\n\".format(val))\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvAiapYI5zHq"
      },
      "source": [
        "Training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_QleYCk51a1"
      },
      "outputs": [],
      "source": [
        "\n",
        "tmp_train_data_dir = os.path.join(TMP_DATA_DIR, \"Final_Training_Images/GTSRB/Final_Training/Images\")\n",
        "\n",
        "directories = [d for d in os.listdir(tmp_train_data_dir) \n",
        "               if os.path.isdir(os.path.join(tmp_train_data_dir, d))]\n",
        "\n",
        "ppm_files_train = []\n",
        "ppm_labels_train = []\n",
        "for class_directory in directories:\n",
        "    label_dir = os.path.join(tmp_train_data_dir, class_directory)\n",
        "    file_names = [os.path.join(label_dir, f) \n",
        "                  for f in os.listdir(label_dir) if f.endswith(\".ppm\")]\n",
        "    for image_file in file_names:\n",
        "        ppm_files_train.append(image_file)\n",
        "        ppm_labels_train.append(class_directory)\n",
        "        \n",
        "ppm_files_train.sort()\n",
        "ppm_labels_train.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uheh5KWJ55cI"
      },
      "outputs": [],
      "source": [
        "# wprowadzenie skali szarości, wyrównanie histogramu, konwersja z .ppm na .jpg\n",
        "for ppm_file, label in zip(ppm_files_train, ppm_labels_train):\n",
        "    image = Image.open(ppm_file)\n",
        "    gray_image = cv2.cvtColor(np.uint8(image), cv2.COLOR_BGR2GRAY)\n",
        "    eq_image = cv2.equalizeHist(gray_image)\n",
        "    directory = os.path.join(TRAINING_DATA_DIR, label)\n",
        "    image_filename = \"{}.jpg\".format(os.path.splitext(os.path.basename(ppm_file))[0])\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    \n",
        "    # gray_image.save(os.path.join(directory, image_filename))\n",
        "    cv2.imwrite(os.path.join(directory, image_filename), eq_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiCuxLnC6ASc"
      },
      "outputs": [],
      "source": [
        "# przykładowy obraz każdego ze znaków ze zbioru danych\n",
        "preprocessed_training_dirs = [d for d in os.listdir(TRAINING_DATA_DIR) \n",
        "               if os.path.isdir(os.path.join(TRAINING_DATA_DIR, d))]\n",
        "preprocessed_training_dirs.sort()\n",
        "\n",
        "training_images = []\n",
        "for training_dir in preprocessed_training_dirs:\n",
        "    training_images.append(os.path.join(TRAINING_DATA_DIR, training_dir, \"00000_00000.jpg\"))\n",
        "\n",
        "\n",
        "label_number = list(label_map.keys())\n",
        "i = 0\n",
        "plt.figure(figsize=(17, 30))\n",
        "for image in training_images:\n",
        "    plt.subplot(10,7, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"{}\".format(label_map[label_number[i]]))\n",
        "    i += 1\n",
        "    plt.imshow(Image.open(image))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NBTinmn6A8s"
      },
      "outputs": [],
      "source": [
        "# normalizacja\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
        "# liczba obrazów i liczba klas\n",
        "image_data = image_generator.flow_from_directory(str(TRAINING_DATA_DIR), target_size=IMAGE_SHAPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbUtmXrD6Iln"
      },
      "outputs": [],
      "source": [
        "# kształt partii obrazu i etykiety\n",
        "for image_batch, label_batch in image_data:\n",
        "  print(\"Image batch shape: \", image_batch.shape)\n",
        "  print(\"Label batch shape: \", label_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FqvVmoX6JpJ"
      },
      "source": [
        "Validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XC6hkWbO6L90"
      },
      "outputs": [],
      "source": [
        "# wczytanie zbioru testowego\n",
        "tmp_validation_data_dir = os.path.join(TMP_DATA_DIR, \"Final_Test_Images/GTSRB/Final_Test/Images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73ouumE16PX8"
      },
      "outputs": [],
      "source": [
        "tmp_validation_data_files = [f for f in os.listdir(tmp_validation_data_dir) if f.endswith(\".ppm\")]\n",
        "validation_images = []\n",
        "\n",
        "# eksport plików .jpg\n",
        "for ppm_file in tmp_validation_data_files:\n",
        "    image_dir = os.path.join(tmp_validation_data_dir, ppm_file) \n",
        "    image = Image.open(image_dir)\n",
        "    gray_image = cv2.cvtColor(np.uint8(image), cv2.COLOR_BGR2GRAY)\n",
        "    eq_image = cv2.equalizeHist(gray_image)\n",
        "    directory = VALIDATION_DATA_DIR\n",
        "    image_filename = \"{}.jpg\".format(os.path.splitext(os.path.basename(ppm_file))[0])\n",
        "\n",
        "    \n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        \n",
        "    final_image = os.path.join(directory, image_filename)\n",
        "    # final_image = cv2.imwrite(os.path.join(directory, image_filename), eq_image)\n",
        "    image.save(final_image)\n",
        "\n",
        "    validation_images.append(final_image)\n",
        "    validation_images.sort()\n",
        "    \n",
        "print(\"Validation images count:\", len(validation_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS7eB0ed6Y1W"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDc4HsZg6Rkf"
      },
      "outputs": [],
      "source": [
        "# headless model \n",
        "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\" \n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
        "                                         input_shape=(224,224,3))\n",
        "# returns: size of detected object, vector for each image\n",
        "feature_batch = feature_extractor_layer(image_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8VFlaN46caR"
      },
      "outputs": [],
      "source": [
        "# false, beacuse next blocks affects next layers\n",
        "feature_extractor_layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yc6wKomQ6e51"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_extractor_layer,\n",
        "  layers.Dense(image_data.num_classes)\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDikGPjv6jLb"
      },
      "outputs": [],
      "source": [
        "# the output of an algorithm after it has been trained on a historical \n",
        "# dataset and applied to new data when forecasting the likelihood of a particular outcome\n",
        "predictions = model(image_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS76DwKG6lDa"
      },
      "outputs": [],
      "source": [
        "predictions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGlTxb-g6mnv"
      },
      "source": [
        "Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igoCXjXR6opv"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['acc'], \n",
        "  run_eagerly=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NBG-h6T6qLu"
      },
      "outputs": [],
      "source": [
        "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    self.batch_losses = []\n",
        "    self.batch_acc = []\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    self.batch_losses.append(logs['loss'])\n",
        "    self.batch_acc.append(logs['acc'])\n",
        "    self.model.reset_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyUhJ59i6ra0"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\n",
        " \n",
        "batch_stats_callback = CollectBatchStats()\n",
        " \n",
        "history = model.fit(image_data, epochs=4,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    callbacks=[batch_stats_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOVPfkf26trL"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(batch_stats_callback.batch_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24736lwT6uPZ"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(batch_stats_callback.batch_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pau2OcsB6vzZ"
      },
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaFJ8CqqzRDq"
      },
      "outputs": [],
      "source": [
        "tmp_validation_labels_csv = os.path.join(TMP_DATA_DIR, \"Final_Test_GT/GT-final_test.csv\") \n",
        "val_data_frame = pd.read_csv(tmp_validation_labels_csv, header=0, sep=',') \n",
        "val_data_frame['Filename'] = val_data_frame['Filename'].str.replace('.ppm','.jpg') \n",
        "val_data_frame['ClassId'] = val_data_frame['ClassId'].astype(str).str.zfill(5)\n",
        "\n",
        "image_val_data = image_generator.flow_from_dataframe(val_data_frame, x_col=\"Filename\", directory=VALIDATION_DATA_DIR, y_col=\"ClassId\", target_size=IMAGE_SHAPE) #(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lha0biXW61YI"
      },
      "outputs": [],
      "source": [
        "for image_val_batch, label_val_batch in image_val_data:\n",
        "  print(\"Image batch shape: \", image_val_batch.shape)\n",
        "  print(\"Label batch shape: \", label_val_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbMOGnDM6yI6"
      },
      "outputs": [],
      "source": [
        "predicted_batch = model.predict(image_val_batch)\n",
        "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
        "label_id = np.argmax(label_val_batch, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnNiujB564R5"
      },
      "outputs": [],
      "source": [
        "batch_size = image_val_batch.shape[0]\n",
        "num_plot_column = 5\n",
        "num_plot_row = batch_size // num_plot_column + (batch_size % num_plot_column > 0)\n",
        "\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "label_number = list(label_map.keys())\n",
        "print(label_number)\n",
        "\n",
        "print(\"Accuracy of the shown eval batch:\")\n",
        "accuracy_score(label_id, predicted_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdzPtCGL68df"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(x=image_val_data, batch_size=image_val_data.batch_size, steps=image_val_data.samples/image_val_data.batch_size)\n",
        "print(\"Loss: \", score[0], \"Accuracy: \", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbmC4oQG69jk"
      },
      "source": [
        "# Saving model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8OakcY96_eA"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "t = time.time()\n",
        "\n",
        "export_path = f\"{OUTPUT_ROOT_DIR}/model{int(t)}\"\n",
        "model.save(export_path, save_format='tf')\n",
        "tf.keras.models.save_model(model, export_path)\n",
        "# model.save('saved_model/my_model2', save_format='tf')\n",
        "model.summary()\n",
        "\n",
        "export_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TPq8zzJ7Agp"
      },
      "outputs": [],
      "source": [
        "# converting model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# saving model\n",
        "with tf.io.gfile.GFile(OUTPUT_TFLITE_MODEL, 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model + adding TPU\n",
        "interpreter = tf.lite.Interpreter(model_path=OUTPUT_TFLITE_MODEL)\n",
        "# interpreter = tf.lite.Interpreter(model_path=export_path) #####\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "batch_size = image_val_batch.shape[0]\n",
        "predicted_id = np.zeros(batch_size)\n",
        " \n",
        "for i, image in enumerate(np.split(image_val_batch, batch_size)):\n",
        "  interpreter.set_tensor(input_details[0]['index'], image)\n",
        "  interpreter.invoke()\n",
        "  output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "  predicted_id[i] = np.argmax(output_data)\n",
        "\n",
        "label_id = np.argmax(label_val_batch, axis=-1)\n",
        "\n",
        "num_plot_column = 5\n",
        "num_plot_row = batch_size // num_plot_column + (batch_size % num_plot_column > 0)\n",
        "\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "model.save(f'{OUTPUT_ROOT_DIR}/tpu_saved_model/tf_model')\n",
        "\n",
        "print(\"Accuracy of the shown eval batch, with the TensorFlow Lite model:\")\n",
        "accuracy_score(label_id, predicted_id)"
      ],
      "metadata": {
        "id": "b5d0yNQY5vs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "%cd gdrive/MyDrive/'Colab Notebooks'/\n",
        "%ls\n",
        "!unzip 'tpu_saved_model.zip'"
      ],
      "metadata": {
        "id": "0JLtTgnnCpIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model('tpu_saved_model/tf_model')\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "hF56HvxuDuMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"model.tflite\")"
      ],
      "metadata": {
        "id": "sB9S8As0FD8V",
        "outputId": "2b3e1e35-051e-4261-d7f4-f16d21912d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b7aeaa81-8ecd-4a91-bc02-7f7c7975cf3d\", \"model.tflite\", 8930880)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of ML_ADAS_Raspberry.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}